{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All about testing code\n",
    "\n",
    "following mainly this: https://realpython.com/python-unittest/\n",
    "\n",
    "if you structure your tests in a subfolder manner, make sure to add a `__init__.py` file for every folder, so that vscode does find it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**intro**\n",
    "\n",
    "there are different kind of tests:\n",
    "* An integration test checks that components in your application operate with each other.\n",
    "* A unit test checks a small component in your application.\n",
    "\n",
    "For simple functions i can use **doctest**. Here you write the documentation and and the test in one go. But for more complex scenarios, we need to choose a **test runner**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding tests in square\n",
      "Trying:\n",
      "    square(2)\n",
      "Expecting:\n",
      "    4\n",
      "ok\n",
      "Trying:\n",
      "    square(3)\n",
      "Expecting:\n",
      "    9\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "# simple unit test\n",
    "assert sum([1, 2, 3]) == 6, \"Should be 6\"\n",
    "\n",
    "# doctest\n",
    "\n",
    "import doctest\n",
    "\n",
    "def square(x):\n",
    "    \"\"\"\n",
    "    Squares a number and returns the result.\n",
    "    \n",
    "    >>> square(2)\n",
    "    4\n",
    "    >>> square(3)\n",
    "    9\n",
    "    \"\"\"\n",
    "    return x * x\n",
    "\n",
    "doctest.run_docstring_examples(square, globals(), verbose=True, name='square')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**test runner**\n",
    "\n",
    "there are different ones, but the concepts are similar.\n",
    "- unittest (std lib python)\n",
    "    - Test case: An individual unit of testing. It examines the output for a given input set.\n",
    "    - Test suite: A collection of test cases, test suites, or both. Theyâ€™re grouped and executed as a whole.\n",
    "    - Test fixture: A group of actions required to set up an environment for testing. It also includes the teardown processes after the tests run.\n",
    "    - Test runner: A component that handles the execution of tests and communicates the results to the user.\n",
    "- pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a TestCase, by inheriting from unittest.TestCase\n",
    "# testing the abs() function\n",
    "\n",
    "import unittest\n",
    "\n",
    "class TestAbsFunction(unittest.TestCase):\n",
    "    def test_positive_number(self):\n",
    "        self.assertEqual(abs(10), 10)\n",
    "\n",
    "    def test_negative_number(self):\n",
    "        self.assertEqual(abs(-10), 10)\n",
    "\n",
    "    def test_zero(self):\n",
    "        self.assertEqual(abs(0), 0)\n",
    "\n",
    "# to test a unit checkout age.py (defining the function) and test_age.py (unit test) in the same directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the different assert methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jupyter makes it hard to run the tests... see the python files in this order\n",
    "1. age.py and test_age.py\n",
    "2. test_skipping.py\n",
    "3. iseven.py and test_iseven.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check inside the folder `assert_methods`\n",
    "\n",
    "**boolean comparison**\n",
    "\n",
    "|Method|Comparison|\n",
    "|---|---|\n",
    "|.assertEqual(a, b)\t|a == b|\n",
    "|.assertNotEqual(a, b)\t|a != b|\n",
    "|.assertTrue(x)\t|bool(x) is True|\n",
    "|.assertFalse(x)\t|bool(x) is False|\n",
    "\n",
    "see this in action with:\n",
    "`prime_v1.py` and `test_prime_v1.py`\n",
    "\n",
    "**identity comparison**\n",
    "|Method|Comparison|\n",
    "|---|---|\n",
    "|.assertIs(a, b)|\ta is b|\n",
    "|.assertIsNot(a, b)|\ta is not b|\n",
    "|.assertIsNone(x)|\tx is None|\n",
    "|.assertIsNotNone(x)|\tx is not None|\n",
    "\n",
    "see this in action with `test_identity.py`\n",
    "\n",
    "**collection comparison**\n",
    "\n",
    "such as lists, tuples, dicts, sets (compares the values)\n",
    "|Method|Comparison|\n",
    "|---|---|\n",
    "|.assertSequenceEqual(a, b)\t|Equality of two sequences|\n",
    "|.assertMultiLineEqual(a, b)|\tEquality of two strings|\n",
    "|.assertListEqual(a, b)\t|Equality of two lists|\n",
    "|.assertTupleEqual(a, b)|\tEquality of two tuples|\n",
    "|.assertDictEqual(a, b)\t|Equality of two dictionaries|\n",
    "|.assertSetEqual(a, b)\t|Equality of two sets|\n",
    "\n",
    "see this in action with `test_collections.py`\n",
    "\n",
    "**test membership**\n",
    "|Method|Comparison|\n",
    "|---|---|\n",
    ".assertIn(a, b)\t|a in b\n",
    "|.assertNotIn(a, b)|\ta not in b|\n",
    "\n",
    "see in action here `test_membership.py`\n",
    "\n",
    "**test object type**\n",
    "|Method|Comparison|\n",
    "|---|---|\n",
    "|.assertIsInstance(a, b)\t|isinstance(a, b)|\n",
    "|.assertNotIsInstance(a, b)|\tnot isinstance(a, b)|\n",
    "\n",
    "see in action in `vehicles.py` and `test_vehicles.py`\n",
    "\n",
    "**testing for exceptions**\n",
    "|Method|Comparison|\n",
    "|---|---|\n",
    "|.assertRaises(exc, fun, *args, **kwds)\tfun(*args, **kwds) |raises exc|\n",
    "|.assertRaisesRegex(exc, r, fun, *args, **kwds)\tfun(*args, **kwds)| raises exc and the message matches regex r|\n",
    "\n",
    "see in action in `prime_v2.py` and `test_prime_v2.py`\n",
    "\n",
    "**test for warnings and logs**\n",
    "\n",
    "warnings are a special category of exceptions. A common warning is a DeprecationWarning\n",
    "|Method|Comparison|\n",
    "|---|---|\n",
    "|.assertWarns(warn, fun, *args, **kwds)|\tfun(*args, **kwds) raises warn|\n",
    "|.assertWarnsRegex(warn, r, fun, *args, **kwds)|\tfun(*args, **kwds) raises warn and the message matches regex r|\n",
    "|.assertLogs(logger, level)|\tThe with block logs on logger with minimum level|\n",
    "|.assertNoLogs(logger, level)|\tThe with block does not log on logger with minimum level|\n",
    "\n",
    "**custom**\n",
    "\n",
    "you can also define custom assert methods. see `test_custom.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check inside the folder ``assert_methods``\n",
    "\n",
    "unittest has something called `TestSuite` that lets you group tests. See in action in `calculations.py` and `test_calculations.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test fixtures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a test fixture is a preparation that you perform before and after running one or more tests. The perparation before are known as **setup** (create temp files, objects, network connections...) and the ones after **teardown** (release/close/delete... the setup objects).\n",
    "\n",
    "you can overwrite the following methods\n",
    "\n",
    "|Method|\tDescription|\n",
    "|---|---|\n",
    "|.setUp()\t    |An instance method that unittest calls before running each test method in a test case class.|\n",
    "|.tearDown()\t|An instance method that unittest calls after running each test method in a test case class.|\n",
    "|.setUpClass()\t|A class method that unittest calls before running the tests in a test case class.|\n",
    "|.tearDownClass()\t|A class method that unittest calls after running the tests in a test case class.|\n",
    "\n",
    "the last two are classmethods, so use the @classmethod decorator. These methods take the current test class as an arg. They only run once per class\n",
    "```python\n",
    "import unittest\n",
    "\n",
    "class Test(unittest.TestCase):\n",
    "    @classmethod\n",
    "    def setUpClass(cls):\n",
    "        ...\n",
    "\n",
    "    @classmethod\n",
    "    def tearDownClass(cls):\n",
    "        ...\n",
    "```\n",
    "\n",
    "you can also create module level fixtures - you need to use **module-level functions** rather than methods on a TestCase subclass. The required functions are\n",
    "|Method|\tDescription|\n",
    "|---|---|\n",
    "|setUpModule()|\tRuns before all test cases in the containing module|\n",
    "|tearDownModule()|\tRuns after all test cases have run|\n",
    "\n",
    "if an exception occurs in the setupModule() function, the none of the tests in the module run, the teardown method won't run eighter. Use these, when you have several TestCase subclasses in a module and some of them will benefit from a setup and teardown logic. A common example are database related functionalities - these tests need an active connection\n",
    "\n",
    "see these in action in the folder ``fixtures``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing with fake objects: mock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see in the `mocks` folder\n",
    "\n",
    "simulate external obj, like files, connectsion...\n",
    "\n",
    "1. Mock is a general generic mock object\n",
    "2. MagicMock is the same as Mock, but it includes magic methods (`__str__()`...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "infobrainy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
